{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b7ed223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"OBJC_DISABLE_INITIALIZE_FORK_SAFETY\"] = \"YES\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49397e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build connection\n",
    "spark = SparkSession.builder. \\\n",
    "    master(\"local[*]\"). \\\n",
    "    appName(\"PySpark\"). \\\n",
    "    config(\"spark.driver.memory\",\"16g\"). \\\n",
    "    config(\"spark.driver.maxResultSize\", \"4g\"). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5b86c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "data_path = 'data/convincing_data.csv'\n",
    "data = spark.read.option(\"header\",True).csv(data_path).rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a602cf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(type='comment', id='imlcpab', subreddit.id='2qh1i', subreddit.name='askreddit', subreddit.nsfw='False', created_utc='1661990065', permalink='https://old.reddit.com/r/AskReddit/comments/x2fj3g/whats_a_controversial_topic_no_one_wants_to/imlcpab/', sentiment='0.469', score='2', body_cleaned=\"['need', 'chang', 'law', 'worth', 'sell', 'agricultur', 'product', 'us', 'rather', 'export', 'also', 'need', 'chang', 'law', 'monetari', 'penalti', 'grow', 'crop', 'particular', 'viabl', 'area', 'natur', 'climat', 'stand', 'right', 'neighbor', 'make', 'doubl', 'price', 'per', 'head', 'cattl', 'export', 'countri', 'would', 'sell', 'right', 'peopl', 'complain', 'climat', 'chang', 'probabl', 'complain']\", climate_count='2', change_count='3', body_length='403', climate_proportion='0.004962779156327543', change_proportion='0.007444168734491315')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87cf87e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_label(score):\n",
    "    if score>0: return 1\n",
    "    elif score<0: return -1\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c78a6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_label_content = data.map(lambda x: (x['id'], score_label(float(x['sentiment'])), x['body_cleaned']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0da1380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "def evaluation(y, y_pred):\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred, average='weighted')\n",
    "    recall = recall_score(y, y_pred, average='weighted')\n",
    "    f1 = f1_score(y, y_pred, average='weighted')\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aeefcc",
   "metadata": {},
   "source": [
    "### AFINN lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "104da94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install afinn\n",
    "from afinn import Afinn\n",
    "afinn = Afinn()\n",
    "id_label_score_afinn = id_label_content.map(lambda x: (x[0], x[1], afinn.score(x[2])))   \n",
    "id_true_pred_afinn = id_label_score_afinn.map(lambda x: (x[0], x[1], score_label(x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e414f52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Precision, Recall, F1: (0.7044006446364192, 0.7524181936953306, 0.7044006446364192, 0.7237871614428109)\n",
      "CPU times: user 846 ms, sys: 157 ms, total: 1 s\n",
      "Wall time: 4min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res_afinn = pd.DataFrame(id_true_pred_afinn.collect())\n",
    "print('Accuracy, Precision, Recall, F1:', evaluation(res_afinn.iloc[:,1],res_afinn.iloc[:,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6233d1f7",
   "metadata": {},
   "source": [
    "### VADER lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8bd0153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "id_label_score_vader = id_label_content.map(lambda x: (x[0], x[1], analyzer.polarity_scores(x[2])['compound']))  \n",
    "id_true_pred_vader = id_label_score_vader.map(lambda x: (x[0], x[1], score_label(x[2])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1073840",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Precision, Recall, F1: (0.7603382226251592, 0.7711465291335221, 0.7603382226251592, 0.7628042003837002)\n",
      "CPU times: user 834 ms, sys: 128 ms, total: 962 ms\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res_vader = pd.DataFrame(id_true_pred_vader.collect())\n",
    "print('Accuracy, Precision, Recall, F1:', evaluation(res_vader.iloc[:,1],res_vader.iloc[:,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2da034",
   "metadata": {},
   "source": [
    "### Hu and Liu Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f8500f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = pd.read_csv('https://raw.githubusercontent.com/jeffreybreen/twitter-sentiment-analysis-tutorial-201107/master/data/opinion-lexicon-English/positive-words.txt',\n",
    "                        names=['word'], comment=';', encoding='latin-1')['word'].tolist()\n",
    "negative_words = pd.read_csv('https://raw.githubusercontent.com/jeffreybreen/twitter-sentiment-analysis-tutorial-201107/master/data/opinion-lexicon-English/negative-words.txt',\n",
    "                        names=['word'], comment=';', encoding='latin-1')['word'].tolist()\n",
    "\n",
    "def get_sentiment_huliu(words):\n",
    "    # Define variables to keep track of the positive and negative scores\n",
    "    pos_score = 0\n",
    "    neg_score = 0\n",
    "    \n",
    "    # Loop through each word and check if it's in the positive or negative word list\n",
    "    for word in words:\n",
    "        if word in positive_words:\n",
    "            pos_score += 1\n",
    "        elif word in negative_words:\n",
    "            neg_score += 1\n",
    "    # print(pos_score,neg_score)\n",
    "    # Calculate the sentiment score for the text\n",
    "    if pos_score > neg_score:\n",
    "        return 1\n",
    "    elif pos_score < neg_score:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6626a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_true_pred_huliu = id_label_content.map(lambda x: (x[0], x[1], get_sentiment_huliu(x[2].strip('[]').replace(\"'\",'').split(', '))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14fa35cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Precision, Recall, F1: (0.614468788289387, 0.7086152519485013, 0.614468788289387, 0.6536469527999506)\n",
      "CPU times: user 905 ms, sys: 113 ms, total: 1.02 s\n",
      "Wall time: 11min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res_huliu = pd.DataFrame(id_true_pred_huliu.collect())\n",
    "print('Accuracy, Precision, Recall, F1:', evaluation(res_huliu.iloc[:,1],res_huliu.iloc[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89fcfd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0168dd2",
   "metadata": {},
   "source": [
    "### SentiWordNet Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606f2b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def get_sentiment_nltk(words):\n",
    "    pos_score = 0\n",
    "    neg_score = 0\n",
    "    obj_score = 0\n",
    "    for word in words:\n",
    "        synsets = wn.synsets(word)\n",
    "        if synsets:\n",
    "            swn_synset = swn.senti_synset(synsets[0].name())\n",
    "            pos_score += swn_synset.pos_score()\n",
    "            neg_score += swn_synset.neg_score()\n",
    "\n",
    "    # normalize the scores\n",
    "    if pos_score > neg_score:\n",
    "        return 1\n",
    "    elif pos_score < neg_score:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49ec9c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/convincing_data.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "data = data[['id','sentiment','body_cleaned']]\n",
    "data['body_cleaned'] = data['body_cleaned'].apply(lambda x: x.strip('[]').replace(\"'\",'').split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98482f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 54s, sys: 43.8 s, total: 13min 38s\n",
      "Wall time: 1h 22min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['sentiment_pred'] = data['body_cleaned'].apply(lambda x: get_sentiment_nltk(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72ebb8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'] = data['sentiment'].apply(lambda x: score_label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd10ecc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Precision, Recall, F1: (0.5750066620889773, 0.5955107442904731, 0.5750066620889773, 0.5820972858699276)\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy, Precision, Recall, F1:', evaluation(data.iloc[:,1],data.iloc[:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c82759e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
