{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bUcFp4V_E2e-"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import lightgbm as lgb\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from time import time\n",
        "import pickle\n",
        "import scipy.sparse as sp\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy.sparse import hstack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSQiOsy7E8hi",
        "outputId": "86e31977-2e73-4a11-f654-82c0144b0558"
      },
      "outputs": [],
      "source": [
        "# connect to colab, or you can use local path\n",
        "#drive.mount('/content/drive/')\n",
        "#dirpath = '/content/drive/MyDrive/climate change/'\n",
        "#load data\n",
        "df = pd.read_csv('convincing_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jl9m4SqpFh7Q"
      },
      "outputs": [],
      "source": [
        "# sentiment score, using -1/3, 1/3 as split line, this way the perfromance is better\n",
        "def sentimentClassify(sentiment_label):\n",
        "  if -1 <= sentiment_label < -1+2/3:\n",
        "    return -1\n",
        "  elif -1+2/3 <= sentiment_label < -1+4/3:\n",
        "    return 0\n",
        "  elif -1+4/3 <= sentiment_label <= 1:\n",
        "    return 1\n",
        "df['sentiment_tri'] = df['sentiment'].apply(sentimentClassify)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "KTnGkTqOfSFF",
        "outputId": "add7b368-2867-4d63-b137-179a46c0d123"
      },
      "outputs": [],
      "source": [
        "# using -0.5 0.5 as split line\n",
        "def map_sentiment_label(sentiment_label):\n",
        "    if sentiment_label > 0.5:\n",
        "        return 1\n",
        "    elif sentiment_label < -0.5:\n",
        "        return -1\n",
        "    else:\n",
        "        return 0\n",
        "df['sentiment_tri'] = df['sentiment'].apply(map_sentiment_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9FwI2oaDRV7v"
      },
      "outputs": [],
      "source": [
        "#########################\n",
        "# process comments so that we can calculate tf-idf\n",
        "comments = df['body_cleaned']\n",
        "words_list = comments.apply(lambda x:re.split(r\"[\\[,'\\]\\s]+\", x)[1:])\n",
        "wordslist = words_list.apply(lambda x: ' '.join(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Hx7k4NyC32o9"
      },
      "outputs": [],
      "source": [
        "df['words_list'] = wordslist\n",
        "Dataset = df[['words_list','score','body_length','sentiment_tri']]\n",
        "#Dataset.to_csv('DataSet.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lJo7scOM6zxI"
      },
      "outputs": [],
      "source": [
        "# Read the processed data directly if kernel crushes\n",
        "#Dataset = pd.read_csv('DataSet.csv')\n",
        "#wordslist = Dataset['words_list']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tbB74G0zfSFH"
      },
      "outputs": [],
      "source": [
        "# calculate tf-idf\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
        "tfidf_comments = tfidf_vectorizer.fit_transform(wordslist)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgxttgdQi4Fu"
      },
      "outputs": [],
      "source": [
        "# If use other attributes like body_lenght, score, then use this part\n",
        "\n",
        "import scipy.sparse as sp\n",
        "from scipy.sparse import csr_matrix\n",
        "# transfer score and body_leangth to sparse matrix so that they could concat with tf-idf comments vector\n",
        "score_sparse = csr_matrix.transpose(sp.csr_matrix(Dataset['score']))\n",
        "body_length_sparse = csr_matrix.transpose(sp.csr_matrix(Dataset['body_length']))\n",
        "\n",
        "X_with_attrs = sp.hstack([tfidf_comments, score_sparse, body_length_sparse]) # 将X和attrs_sparse水平合并\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Initialize TruncatedSVD model, setting dimensions\n",
        "svd = TruncatedSVD(n_components=1000)\n",
        "\n",
        "# 对稀疏矩阵进行降维\n",
        "X = svd.fit_transform(X_with_attrs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "## If only use comments, then use tf-idf matrix as X data set\n",
        "X = tfidf_comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Y = pd.read_csv('DataSet_Y.csv',index_col=0)\n",
        "Y = Dataset['sentiment_tri']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ll1k-apL4wzS"
      },
      "outputs": [],
      "source": [
        "#########################\n",
        "# split data set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "yOXLtK-rnym1",
        "outputId": "c5ea2396-25a4-4b19-a29f-d7fb01e38e23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 61.95776104927063 seconds ---\n",
            "Training accuracy 0.7200\n",
            "Testing accuracy 0.6962\n"
          ]
        }
      ],
      "source": [
        "# LightGBM Training\n",
        "start_time = time()\n",
        "from lightgbm import LGBMClassifier\n",
        "lgbm_clf=LGBMClassifier(boosting_type='gbdt', class_weight=None, \n",
        "               learning_rate=0.1, max_depth=6, n_estimators=300, \n",
        "               reg_alpha=0.0, reg_lambda=0.0,\n",
        "               colsample_bytree=1.0, subsample=1.0,\n",
        "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0, num_leaves=100,\n",
        "               n_jobs=-1, objective='multiclass', importance_type='split',\n",
        "               random_state=42)\n",
        "lgbm_clf.fit(X_train,y_train)\n",
        "print(\"--- %s seconds ---\" % (time() - start_time))\n",
        "print('Training accuracy {:.4f}'.format(lgbm_clf.score(X_train,y_train)))\n",
        "print('Testing accuracy {:.4f}'.format(lgbm_clf.score(X_test,y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.60      0.78      0.68     59343\n",
            "           0       0.39      0.00      0.00     24013\n",
            "           1       0.65      0.71      0.68     58492\n",
            "\n",
            "    accuracy                           0.62    141848\n",
            "   macro avg       0.54      0.50      0.45    141848\n",
            "weighted avg       0.58      0.62      0.56    141848\n",
            "\n",
            "0.35368800163269043\n"
          ]
        }
      ],
      "source": [
        "# Naive Bayes model training\n",
        "start = time()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(time()-start)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
