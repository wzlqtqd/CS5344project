{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ed223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"OBJC_DISABLE_INITIALIZE_FORK_SAFETY\"] = \"YES\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49397e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build connection\n",
    "spark = SparkSession.builder. \\\n",
    "    master(\"local[*]\"). \\\n",
    "    appName(\"PySpark\"). \\\n",
    "    config(\"spark.driver.memory\",\"16g\"). \\\n",
    "    config(\"spark.driver.maxResultSize\", \"4g\"). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b86c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "data_path = 'data/convincing_data.csv'\n",
    "data = spark.read.option(\"header\",True).csv(data_path).rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a602cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf87e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_label(score):\n",
    "    if score>0: return 1\n",
    "    elif score<0: return -1\n",
    "    else: return 0\n",
    "        \n",
    "id_label_content = data.map(lambda x: (x['id'], score_label(float(x['sentiment'])), x['body_cleaned']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da1380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "def evaluation(y, y_pred):\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred, average='weighted')\n",
    "    recall = recall_score(y, y_pred, average='weighted')\n",
    "    f1 = f1_score(y, y_pred, average='weighted')\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aeefcc",
   "metadata": {},
   "source": [
    "### AFINN lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104da94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install afinn\n",
    "from afinn import Afinn\n",
    "afinn = Afinn()\n",
    "id_label_score_afinn = id_label_content.map(lambda x: (x[0], x[1], afinn.score(x[2])))   \n",
    "id_true_pred_afinn = id_label_score_afinn.map(lambda x: (x[0], x[1], score_label(x[2])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e414f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res_afinn = pd.DataFrame(id_true_pred_afinn.collect())\n",
    "print('Accuracy, Precision, Recall, F1:', evaluation(res_afinn.iloc[:,1],res_afinn.iloc[:,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6233d1f7",
   "metadata": {},
   "source": [
    "### VADER lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd0153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "id_label_score_vader = id_label_content.map(lambda x: (x[0], x[1], analyzer.polarity_scores(x[2])['compound']))  \n",
    "id_true_pred_vader = id_label_score_vader.map(lambda x: (x[0], x[1], score_label(x[2])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1073840",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "res_vader = pd.DataFrame(id_true_pred_vader.collect())\n",
    "print('Accuracy, Precision, Recall, F1:', evaluation(res_vader.iloc[:,1],res_vader.iloc[:,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2da034",
   "metadata": {},
   "source": [
    "### Hu and Liu Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8500f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = pd.read_csv('https://raw.githubusercontent.com/jeffreybreen/twitter-sentiment-analysis-tutorial-201107/master/data/opinion-lexicon-English/positive-words.txt',\n",
    "                        names=['word'], comment=';', encoding='latin-1')['word'].tolist()\n",
    "negative_words = pd.read_csv('https://raw.githubusercontent.com/jeffreybreen/twitter-sentiment-analysis-tutorial-201107/master/data/opinion-lexicon-English/negative-words.txt',\n",
    "                        names=['word'], comment=';', encoding='latin-1')['word'].tolist()\n",
    "\n",
    "def get_sentiment_huliu(words):\n",
    "    # Define variables to keep track of the positive and negative scores\n",
    "    pos_score = 0\n",
    "    neg_score = 0\n",
    "    \n",
    "    # Loop through each word and check if it's in the positive or negative word list\n",
    "    for word in words:\n",
    "        if word in positive_words:\n",
    "            pos_score += 1\n",
    "        elif word in negative_words:\n",
    "            neg_score += 1\n",
    "    \n",
    "    # Calculate the sentiment score for the text\n",
    "    if pos_score > neg_score:\n",
    "        return 1\n",
    "    elif pos_score < neg_score:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "id_true_pred_huliu = id_label_content.map(lambda x: (x[0], x[1], get_sentiment_huliu(x[2])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa35cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res_huliu = pd.DataFrame(id_true_pred_huliu.collect())\n",
    "print('Accuracy, Precision, Recall, F1:', evaluation(res_huliu.iloc[:,1],res_vader.iloc[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fcfd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0168dd2",
   "metadata": {},
   "source": [
    "### SentiWordNet Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606f2b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def get_sentiment_nltk(words):\n",
    "    pos_score = 0\n",
    "    neg_score = 0\n",
    "    obj_score = 0\n",
    "    for word in words:\n",
    "        synsets = wn.synsets(word)\n",
    "        if synsets:\n",
    "            swn_synset = swn.senti_synset(synsets[0].name())\n",
    "            pos_score += swn_synset.pos_score()\n",
    "            neg_score += swn_synset.neg_score()\n",
    "\n",
    "    # normalize the scores\n",
    "    if pos_score > neg_score:\n",
    "        return 1\n",
    "    elif pos_score < neg_score:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "id_true_pred_nltk = id_label_content.map(lambda x: (x[0], x[1], get_sentiment_nltk(x[2])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ec9c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path)\n",
    "data = data[['id','sentiment','body_cleaned']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
